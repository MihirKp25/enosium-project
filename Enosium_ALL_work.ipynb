{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FLud1n-3pVm"
      },
      "source": [
        "# CatBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO8VPU6n3vES"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-_d2lI45wQi"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clDSsF7P33NU"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGpwK5XD386E"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zcksk88u4Ae8"
      },
      "source": [
        "dataset = pd.read_csv('Track_1 - Copy.csv')\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "y=y-1"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1 = pd.read_csv('testing_data.csv')\n",
        "lopa = dataset1.iloc[:, :].values"
      ],
      "metadata": {
        "id": "B8n4Vw3N9NoV"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NKpnx9yx9NtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(sparse=False), [0,1,2,3,4,5,6,7,8,9,10,11,12])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))\n",
        "X[0]"
      ],
      "metadata": {
        "id": "bMToJ4I9PuH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNn2RnST6_Q-"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajhBL-er7Gry"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "id": "P_64c9YkPj4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann = tf.keras.models.Sequential()\n",
        "ann.add(tf.keras.layers.Dense(units=4096, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dropout(0.2))\n",
        "ann.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dropout(0.2))\n",
        "ann.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "tE-UGZTFJ82s"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.asarray(X_train).astype('float32')\n",
        "X_test = np.asarray(X_test).astype('float32')\n",
        "y_train = np.asarray(y_train).astype('float32')\n",
        "y_test = np.asarray(y_test).astype('float32')"
      ],
      "metadata": {
        "id": "q35_P2ujLEqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "GEFUWuf4-Vdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics='accuracy')"
      ],
      "metadata": {
        "id": "tEiCE8aRKPEK"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
      ],
      "metadata": {
        "id": "xeK9GzzdL7Qf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "608f1b28-23fe-4287-a420-8ace4665539e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "22/22 [==============================] - 1s 15ms/step - loss: 0.2377 - accuracy: 0.6229\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.1982 - accuracy: 0.6943\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.1910 - accuracy: 0.7143\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.1786 - accuracy: 0.7400\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.1767 - accuracy: 0.7443\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.1593 - accuracy: 0.7557\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.1491 - accuracy: 0.7771\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.1549 - accuracy: 0.7771\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.1419 - accuracy: 0.8000\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.1327 - accuracy: 0.8229\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.1343 - accuracy: 0.8143\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.1274 - accuracy: 0.8314\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.1162 - accuracy: 0.8414\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.1110 - accuracy: 0.8586\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.1173 - accuracy: 0.8486\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.1136 - accuracy: 0.8486\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.1138 - accuracy: 0.8443\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.1052 - accuracy: 0.8643\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.1039 - accuracy: 0.8643\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0975 - accuracy: 0.8757\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.1087 - accuracy: 0.8529\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0978 - accuracy: 0.8700\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.1068 - accuracy: 0.8514\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0902 - accuracy: 0.8829\n",
            "Epoch 25/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0888 - accuracy: 0.8829\n",
            "Epoch 26/100\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.0812 - accuracy: 0.8857\n",
            "Epoch 27/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0758 - accuracy: 0.9029\n",
            "Epoch 28/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0747 - accuracy: 0.9057\n",
            "Epoch 29/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0784 - accuracy: 0.8957\n",
            "Epoch 30/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0822 - accuracy: 0.8957\n",
            "Epoch 31/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0790 - accuracy: 0.9014\n",
            "Epoch 32/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0727 - accuracy: 0.9029\n",
            "Epoch 33/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0626 - accuracy: 0.9243\n",
            "Epoch 34/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0659 - accuracy: 0.9200\n",
            "Epoch 35/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0598 - accuracy: 0.9243\n",
            "Epoch 36/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0617 - accuracy: 0.9200\n",
            "Epoch 37/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0646 - accuracy: 0.9071\n",
            "Epoch 38/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0612 - accuracy: 0.9186\n",
            "Epoch 39/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0684 - accuracy: 0.9057\n",
            "Epoch 40/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0588 - accuracy: 0.9186\n",
            "Epoch 41/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0549 - accuracy: 0.9286\n",
            "Epoch 42/100\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.0509 - accuracy: 0.9357\n",
            "Epoch 43/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0497 - accuracy: 0.9386\n",
            "Epoch 44/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0551 - accuracy: 0.9271\n",
            "Epoch 45/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0514 - accuracy: 0.9257\n",
            "Epoch 46/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0495 - accuracy: 0.9329\n",
            "Epoch 47/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0471 - accuracy: 0.9457\n",
            "Epoch 48/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0466 - accuracy: 0.9386\n",
            "Epoch 49/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0488 - accuracy: 0.9414\n",
            "Epoch 50/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0376 - accuracy: 0.9500\n",
            "Epoch 51/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0417 - accuracy: 0.9400\n",
            "Epoch 52/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0410 - accuracy: 0.9471\n",
            "Epoch 53/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0421 - accuracy: 0.9457\n",
            "Epoch 54/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0395 - accuracy: 0.9557\n",
            "Epoch 55/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0396 - accuracy: 0.9514\n",
            "Epoch 56/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0421 - accuracy: 0.9457\n",
            "Epoch 57/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0393 - accuracy: 0.9486\n",
            "Epoch 58/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0352 - accuracy: 0.9586\n",
            "Epoch 59/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0354 - accuracy: 0.9571\n",
            "Epoch 60/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0586 - accuracy: 0.9214\n",
            "Epoch 61/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0589 - accuracy: 0.9200\n",
            "Epoch 62/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0432 - accuracy: 0.9429\n",
            "Epoch 63/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0392 - accuracy: 0.9500\n",
            "Epoch 64/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0361 - accuracy: 0.9514\n",
            "Epoch 65/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0350 - accuracy: 0.9643\n",
            "Epoch 66/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0318 - accuracy: 0.9586\n",
            "Epoch 67/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0396 - accuracy: 0.9457\n",
            "Epoch 68/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0396 - accuracy: 0.9529\n",
            "Epoch 69/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0336 - accuracy: 0.9629\n",
            "Epoch 70/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0362 - accuracy: 0.9529\n",
            "Epoch 71/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0330 - accuracy: 0.9571\n",
            "Epoch 72/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0308 - accuracy: 0.9600\n",
            "Epoch 73/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0383 - accuracy: 0.9571\n",
            "Epoch 74/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0384 - accuracy: 0.9500\n",
            "Epoch 75/100\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.0320 - accuracy: 0.9600\n",
            "Epoch 76/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0322 - accuracy: 0.9571\n",
            "Epoch 77/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0314 - accuracy: 0.9629\n",
            "Epoch 78/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0275 - accuracy: 0.9671\n",
            "Epoch 79/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0310 - accuracy: 0.9643\n",
            "Epoch 80/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0291 - accuracy: 0.9671\n",
            "Epoch 81/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0364 - accuracy: 0.9529\n",
            "Epoch 82/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0337 - accuracy: 0.9543\n",
            "Epoch 83/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0295 - accuracy: 0.9671\n",
            "Epoch 84/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0246 - accuracy: 0.9700\n",
            "Epoch 85/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0300 - accuracy: 0.9600\n",
            "Epoch 86/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0311 - accuracy: 0.9571\n",
            "Epoch 87/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0236 - accuracy: 0.9729\n",
            "Epoch 88/100\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.0333 - accuracy: 0.9543\n",
            "Epoch 89/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0312 - accuracy: 0.9586\n",
            "Epoch 90/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0351 - accuracy: 0.9571\n",
            "Epoch 91/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0342 - accuracy: 0.9529\n",
            "Epoch 92/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0306 - accuracy: 0.9586\n",
            "Epoch 93/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0273 - accuracy: 0.9657\n",
            "Epoch 94/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0314 - accuracy: 0.9629\n",
            "Epoch 95/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0303 - accuracy: 0.9600\n",
            "Epoch 96/100\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0224 - accuracy: 0.9700\n",
            "Epoch 97/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0250 - accuracy: 0.9671\n",
            "Epoch 98/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0207 - accuracy: 0.9743\n",
            "Epoch 99/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0244 - accuracy: 0.9671\n",
            "Epoch 100/100\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0318 - accuracy: 0.9571\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fecd05d0760>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = ann.predict(X_test)\n",
        "np.set_printoptions(precision=8)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "metadata": {
        "id": "PKNAjE_yKPKs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a43d4d28-7176-4d8c-ce32-998ea0f64c2f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 5ms/step\n",
            "[[1.38383029e-06 0.00000000e+00]\n",
            " [6.12682216e-02 0.00000000e+00]\n",
            " [1.31022800e-02 0.00000000e+00]\n",
            " [5.56438172e-05 0.00000000e+00]\n",
            " [3.20943967e-02 1.00000000e+00]\n",
            " [9.16703999e-01 1.00000000e+00]\n",
            " [3.69914435e-03 0.00000000e+00]\n",
            " [9.99236524e-01 1.00000000e+00]\n",
            " [9.81452882e-01 1.00000000e+00]\n",
            " [4.27357346e-01 0.00000000e+00]\n",
            " [8.67253959e-01 0.00000000e+00]\n",
            " [9.98998284e-01 1.00000000e+00]\n",
            " [7.35187590e-01 1.00000000e+00]\n",
            " [9.99397814e-01 1.00000000e+00]\n",
            " [1.91491374e-04 0.00000000e+00]\n",
            " [6.26318693e-01 1.00000000e+00]\n",
            " [2.91926056e-01 0.00000000e+00]\n",
            " [3.44813138e-01 0.00000000e+00]\n",
            " [2.63438839e-02 0.00000000e+00]\n",
            " [4.01573834e-06 0.00000000e+00]\n",
            " [2.17145923e-09 0.00000000e+00]\n",
            " [9.99919832e-01 1.00000000e+00]\n",
            " [3.43562956e-10 0.00000000e+00]\n",
            " [3.77570848e-12 0.00000000e+00]\n",
            " [2.94891914e-04 0.00000000e+00]\n",
            " [9.36639309e-01 0.00000000e+00]\n",
            " [8.96405518e-01 0.00000000e+00]\n",
            " [8.60485375e-01 1.00000000e+00]\n",
            " [6.94092214e-02 0.00000000e+00]\n",
            " [8.82742405e-01 1.00000000e+00]\n",
            " [1.71817727e-02 0.00000000e+00]\n",
            " [9.97135520e-01 1.00000000e+00]\n",
            " [7.56087422e-01 0.00000000e+00]\n",
            " [9.69902396e-01 1.00000000e+00]\n",
            " [3.95288168e-07 0.00000000e+00]\n",
            " [1.87036167e-05 0.00000000e+00]\n",
            " [9.95645821e-01 1.00000000e+00]\n",
            " [4.48060382e-06 0.00000000e+00]\n",
            " [1.97462967e-07 0.00000000e+00]\n",
            " [8.98408771e-01 1.00000000e+00]\n",
            " [9.98591483e-01 1.00000000e+00]\n",
            " [9.74910140e-01 0.00000000e+00]\n",
            " [9.66389060e-01 1.00000000e+00]\n",
            " [9.96039867e-01 1.00000000e+00]\n",
            " [9.97433722e-01 1.00000000e+00]\n",
            " [9.99999523e-01 1.00000000e+00]\n",
            " [3.16309175e-12 0.00000000e+00]\n",
            " [9.95380342e-01 1.00000000e+00]\n",
            " [9.95504200e-01 1.00000000e+00]\n",
            " [8.56811881e-01 1.00000000e+00]\n",
            " [9.88910556e-01 1.00000000e+00]\n",
            " [1.54046324e-11 0.00000000e+00]\n",
            " [1.92863663e-04 0.00000000e+00]\n",
            " [9.26034689e-01 1.00000000e+00]\n",
            " [9.99798298e-01 1.00000000e+00]\n",
            " [9.99006391e-01 0.00000000e+00]\n",
            " [1.09923938e-10 0.00000000e+00]\n",
            " [8.22549820e-01 0.00000000e+00]\n",
            " [6.85471520e-02 0.00000000e+00]\n",
            " [3.47132191e-05 0.00000000e+00]\n",
            " [5.46399024e-05 1.00000000e+00]\n",
            " [9.23737228e-01 1.00000000e+00]\n",
            " [9.02316161e-03 0.00000000e+00]\n",
            " [2.96848966e-03 0.00000000e+00]\n",
            " [9.99804854e-01 1.00000000e+00]\n",
            " [9.26360428e-01 0.00000000e+00]\n",
            " [9.88951186e-04 0.00000000e+00]\n",
            " [9.99397814e-01 1.00000000e+00]\n",
            " [9.99618232e-01 1.00000000e+00]\n",
            " [1.31599722e-06 0.00000000e+00]\n",
            " [9.97280359e-01 1.00000000e+00]\n",
            " [1.25542181e-04 0.00000000e+00]\n",
            " [9.98438001e-01 1.00000000e+00]\n",
            " [9.96101558e-01 1.00000000e+00]\n",
            " [3.20943967e-02 1.00000000e+00]\n",
            " [9.97190237e-01 1.00000000e+00]\n",
            " [9.99655366e-01 1.00000000e+00]\n",
            " [9.92359102e-01 1.00000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_1 = ann.predict(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2k8dBcp_UcTr",
        "outputId": "abd11c97-3b83-48f3-cd30-0c40cd9bc609"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_2 = ann.predict(lopa)"
      ],
      "metadata": {
        "id": "CEq6KfBkDoMV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51d25292-b1b3-4b33-db02-9bef9bc184cb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred)"
      ],
      "metadata": {
        "id": "mvr32Yc3GOdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y89ctGZ7Mcx"
      },
      "source": [
        "## Training CatBoost on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ude1J0E47SKN"
      },
      "source": [
        "from catboost import CatBoostClassifier\n",
        "classifier = CatBoostClassifier()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "classifier = XGBClassifier()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "O0T_ERUOYfvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'linear', random_state = 0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "tI2anu1EZuHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "a33iQN2HaCwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "xjJxWRUTaMRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "wnTGDTFHqeXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "oevd3X6xrBUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Mkmbk5ZGrRGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "RTLaZBMLrR4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_train, y_pred_1)\n",
        "print(cm)\n",
        "accuracy_score(y_train, y_pred_1)"
      ],
      "metadata": {
        "id": "t39xIZ0r_nXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuSbAxLIUR04",
        "outputId": "dbcf512a-beee-47b3-f4e3-3889f5cd27d8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[32  8]\n",
            " [ 3 35]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8589743589743589"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "Xo8rifdnTYGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.pop(0)"
      ],
      "metadata": {
        "id": "Bb_jSVQsDty2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UODF3HFpAv4F",
        "outputId": "a0d10b6a-7349-4997-ce76-0ddc0a0d43e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(78, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the lightgbm model\n",
        "import lightgbm as lgb\n",
        "clf = lgb.LGBMClassifier()\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "1NVQphCzbt6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann = tf.keras.models.Sequential()\n",
        "ann.add(tf.keras.layers.Dense(units=1,activation=\"sigmoid\"))\n",
        "ann.fit(X_train,Y_train,batch_size=32,epochs = 100)ann.add(tf.keras.layers.Dense(units=1,activation=\"sigmoid\"))\n",
        "ann.fit(X_train,Y_train,batch_size=32,epochs = 100)"
      ],
      "metadata": {
        "id": "ERWlYHBqdMaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivqmubzW7dFJ"
      },
      "source": [
        "## Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnbCjHgQ8XPn"
      },
      "source": [
        "## Applying k-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYbfiITD8ZAz"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
        "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
        "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (0,78):\n",
        "  if y_pred[i][0]>0.5:\n",
        "    y_pred[i][0]=1\n",
        "  else:\n",
        "    y_pred[i][0]=0"
      ],
      "metadata": {
        "id": "fToiY0ZcHhmy"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (0,156):\n",
        "  if y_pred[i][0]>0.5:\n",
        "    y_pred[i][0]=1\n",
        "  else:\n",
        "    y_pred[i][0]=0"
      ],
      "metadata": {
        "id": "ClXmz8BnCOhM"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8zMCQI1CUtV",
        "outputId": "0f4ea9f9-db8c-426a-d62a-a73907e102be"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (0,700):\n",
        "  if y_pred_1[i][0]>0.5:\n",
        "    y_pred_1[i][0]=1\n",
        "  else:\n",
        "    y_pred_1[i][0]=0"
      ],
      "metadata": {
        "id": "UeblInImUie5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (0,624):\n",
        "  if y_pred_1[i][0]>0.5:\n",
        "    y_pred_1[i][0]=1\n",
        "  else:\n",
        "    y_pred_1[i][0]=0"
      ],
      "metadata": {
        "id": "Pq6oovVUCe4r"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g-HQdgD0Cv3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (0,400):\n",
        "  if y_pred_2[i][0]>0.5:\n",
        "    y_pred_2[i][0]=2\n",
        "  else:\n",
        "    y_pred_2[i][0]=1"
      ],
      "metadata": {
        "id": "q3eo8tH992u_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DCg0F40-PL0",
        "outputId": "eaa1607a-ca7f-4125-e833-ab75059a6543"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "myList = []\n",
        "header=['name','Loan Defaulted or Not']\n",
        "for i in range(0,400):\n",
        "\n",
        "\n",
        "   \n",
        "    score = y_pred_2[i][0]\n",
        "    row = [i+600,str(score)]\n",
        "    myList.append(row)\n",
        "\n",
        "\n",
        "with open('/content/Track_1 - Copy - Copy - Copy.csv', 'w', encoding='UTF8', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "\n",
        "    # write the header\n",
        "    writer.writerow(header)\n",
        "\n",
        "    # write multiple rows\n",
        "    writer.writerows(myList)"
      ],
      "metadata": {
        "id": "M5Ie530J6_I2"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}